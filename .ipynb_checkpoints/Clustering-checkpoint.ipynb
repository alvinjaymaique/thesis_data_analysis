{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5094f04-46e1-439a-b071-19dd7025d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\" Clustering Algorithm \"\"\"\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\"\"\" \n",
    "Metrics for Number of Clusters\n",
    "Note \n",
    "Silhouette Score: The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. \n",
    "Davies Bouldin Score: The minimum score is zero, with lower values indicating better clustering.\n",
    "Calinski Harabasz Score: The score is a positive floating-point value, where higher values indicate better clustering.\n",
    "\"\"\"\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "\"\"\"\n",
    "Scaler for preprocessing\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f8dfa1-2437-4e3f-911f-157996e412b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" The clustering algorithm inside the dictionary datatype or a key-value pair data structure \"\"\"\n",
    "# random_state=42\n",
    "# CLUSTERS_DICT = {\n",
    "#     'kmeans': KMeans(random_state=random_state),\n",
    "#     'spectral': SpectralClustering(random_state=random_state),\n",
    "#     'hierarchical': AgglomerativeClustering(linkage='ward'),\n",
    "#     'agglomerative': AgglomerativeClustering(),\n",
    "#     'gaussian': GaussianMixture(random_state=random_state)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8967731c-2aff-4260-ac59-e6cef2febff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The clustering algorithm and metrics score inside the dictionary datatype or a key-value pair data structure '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" The clustering algorithm and metrics score inside the dictionary datatype or a key-value pair data structure \"\"\"\n",
    "#clusters\n",
    "# CLUSTERS_DICT = {\n",
    "#     'kmeans': KMeans,\n",
    "#     'spectral': SpectralClustering,\n",
    "#     'hierarchical': AgglomerativeClustering,\n",
    "#     'agglomerative': AgglomerativeClustering,\n",
    "#     'gaussian': GaussianMixture\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "758326e5-6f0a-4eb1-b2b5-0e0bc378d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clustering:\n",
    "    \"\"\" Flexible clustering class with optional scaler and metric selection \"\"\"\n",
    "\n",
    "    CLUSTERS_DICT = {\n",
    "        'kmeans': lambda k, random_state: KMeans(n_clusters=k, random_state=random_state),\n",
    "        'spectral': lambda k, random_state: SpectralClustering(n_clusters=k, random_state=random_state, affinity='nearest_neighbors'),\n",
    "        'hierarchical': lambda k, random_state: AgglomerativeClustering(n_clusters=k, linkage='ward'),\n",
    "        'agglomerative': lambda k, random_state: AgglomerativeClustering(n_clusters=k),\n",
    "        'gaussian': lambda k, random_state: GaussianMixture(n_components=k, random_state=random_state),\n",
    "    }\n",
    "\n",
    "    METRICS_DICT = {\n",
    "        'silhouette': silhouette_score,\n",
    "        'davies': davies_bouldin_score,\n",
    "        'calinski': calinski_harabasz_score\n",
    "    }\n",
    "\n",
    "    def __init__(self, X, model, metric='silhouette', scaler_class=None, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.cluster_algo = model\n",
    "        self.metric = metric\n",
    "        self.metric_best_score = None\n",
    "        self.metric_scores = []\n",
    "\n",
    "        # Apply scaling if scaler_class is provided\n",
    "        if scaler_class is not None:\n",
    "            self.scaler = scaler_class()\n",
    "            self.X = self.scaler.fit_transform(X)\n",
    "        else:\n",
    "            self.scaler = None\n",
    "            self.X = X\n",
    "\n",
    "    def find_n_cluster(self, max_range=10):\n",
    "        self.n_cluster, self.metric_best_score = self._compute_n(self.cluster_algo, self.metric, max_range)\n",
    "        return self.n_cluster, self.metric_best_score\n",
    "\n",
    "    def _compute_n(self, cluster_algo, metric, max_range):\n",
    "        self.metric_scores = []\n",
    "        best_score = float('-inf') if metric != 'davies' else float('inf')\n",
    "        best_n_cluster = None\n",
    "\n",
    "        for k in range(2, max_range + 1):\n",
    "            y_labels = self._create_cluster_instance_fit_predict(k)\n",
    "            score = self.METRICS_DICT[metric](self.X, y_labels)\n",
    "            self.metric_scores.append(score)\n",
    "\n",
    "            if (metric == 'davies' and score < best_score) or (metric != 'davies' and score > best_score):\n",
    "                best_score = score\n",
    "                best_n_cluster = k\n",
    "\n",
    "        return best_n_cluster, best_score\n",
    "\n",
    "    def _create_cluster_instance_fit_predict(self, k):\n",
    "        cluster_instance = self.CLUSTERS_DICT[self.cluster_algo](k, self.random_state)\n",
    "\n",
    "        if hasattr(cluster_instance, 'fit_predict'):\n",
    "            return cluster_instance.fit_predict(self.X)\n",
    "\n",
    "        cluster_instance.fit(self.X)\n",
    "        return cluster_instance.predict(self.X)\n",
    "\n",
    "    def get_scaled_data(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            - The scaled (or raw) data\n",
    "            - Name of the scaler used, or 'None'\n",
    "        \"\"\"\n",
    "        scaler_name = type(self.scaler).__name__ if self.scaler else \"None\"\n",
    "        return self.X, scaler_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12bfd9ba-a87e-4810-8d24-b9b3fefcad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Voltage   Current  Power Factor  Frequency     Power\n",
      "0 -9.767521  9.480710      6.487488  -6.462790 -7.361530\n",
      "1 -8.560889  8.734477      6.489258  -4.808246 -6.589762\n",
      "2 -3.327672  7.511521      4.379144   0.847751 -7.028664\n",
      "3 -7.431058 -8.789943      6.635979   1.891384  3.126497\n",
      "4 -8.664148  8.975563      7.325451  -6.289177 -5.823476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "\n",
    "# Generate synthetic dataset\n",
    "n_samples = 500  # Number of data points\n",
    "n_features = 5   # Number of features\n",
    "n_clusters = 3   # Number of clusters\n",
    "\n",
    "X, y = make_blobs(n_samples=n_samples, n_features=n_features, centers=n_clusters, random_state=42)\n",
    "\n",
    "# Convert to a Pandas DataFrame for better visualization\n",
    "columns = ['Voltage', 'Current', 'Power Factor', 'Frequency', 'Power']\n",
    "df = pd.DataFrame(X, columns=columns)\n",
    "# df['Cluster'] = y  # Add cluster labels for reference (optional)\n",
    "\n",
    "print(df.head())  # Show the first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c43f046d-023c-456c-9986-8879877f8f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_sensor_readings = pd.read_csv('Lorega(raw)_anomalous.csv')\n",
    "# df_sensor_readings.head()\n",
    "\n",
    "data_X = df_sensor_readings[['current', 'frequency', 'power', 'powerFactor', 'voltage']]\n",
    "data_X = data_X.dropna()\n",
    "data_X = data_X[:1000]\n",
    "data_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3637dbc-2d47-4f29-a907-d45a78692951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of best cluster: 9; Best Score: 0.6861919127435481;\n"
     ]
    }
   ],
   "source": [
    "kmeans = Clustering(data_X, model='kmeans', scaler_class=StandardScaler)\n",
    "n_cluster, best_score = kmeans.find_n_cluster(max_range=10)\n",
    "print(f'Number of best cluster: {n_cluster}; Best Score: {best_score};')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7d528c4-0f18-4d2d-ae05-b3d37daeb3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.5184147225013972),\n",
       " np.float64(0.5521798703552381),\n",
       " np.float64(0.6485967052822541),\n",
       " np.float64(0.649231973785181),\n",
       " np.float64(0.650886668730593),\n",
       " np.float64(0.5949171162031216),\n",
       " np.float64(0.6352412101006863),\n",
       " np.float64(0.6861919127435481),\n",
       " np.float64(0.6629215082413686)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.metric_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6480bf8-92f8-4208-833e-c3213b2a7dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: StandardScaler\n"
     ]
    }
   ],
   "source": [
    "scaled_data, scaler = kmeans.get_scaled_data()\n",
    "print(f'Scaler: {scaler}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24f1a29d-1105-4d0a-8896-036847a732c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.75249189e-02, -7.83807980e-01,  2.86838605e-02,\n",
       "         4.61199504e-02,  6.38107591e-01],\n",
       "       [-6.96022754e+00, -7.83807980e-01, -6.35192589e+00,\n",
       "         6.33635243e-01,  3.29843054e-01],\n",
       "       [-1.98246471e+01, -7.83807980e-01, -1.93914765e+01,\n",
       "        -2.87421294e+01,  8.43617282e-01],\n",
       "       ...,\n",
       "       [ 3.90869353e-01, -7.83807980e-01,  2.49248148e-01,\n",
       "         4.61199504e-02, -1.82800870e+00],\n",
       "       [ 4.02880949e-01, -7.83807980e-01,  2.43996617e-01,\n",
       "         4.61199504e-02, -2.03351839e+00],\n",
       "       [ 4.14892545e-01, -7.83807980e-01,  2.49248148e-01,\n",
       "         4.61199504e-02, -2.03351839e+00]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302fbb84-5f81-498c-b02a-09fbe6b9162e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
