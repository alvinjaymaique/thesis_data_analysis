Chapter 4: Results and Discussion
4.1 Anomaly Detection Results
4.1.1 Clustering Performance Evaluation
In this study, five clustering algorithms were evaluated for their effectiveness in identifying power quality anomalies in sensor readings: K-Means, Spectral Clustering, Agglomerative Clustering, Ward Hierarchical Clustering, and Gaussian Mixture Model. These algorithms were selected based on their diverse approaches to cluster formation and their suitability for identifying distinct patterns in multidimensional power quality data.

Clustering Algorithm Performance Comparison
The table below presents the performance metrics for each algorithm evaluated on the sensor dataset:
Algorithm
Silhouette Score
Davies-Bouldin Index
Calinski-Harabasz Index
Number of Clusters
KMeans
0.5321
0.8690
17239.31
15
SpectralClustering
-0.0949
1.9033
37.67
4
AgglomerativeClustering
0.5066
0.8446
15943.21
12
WardHierarchical
0.5066
0.8446
15943.21
12
GaussianMixture
0.4806
0.9706
13172.41
6


These metrics provide different perspectives on clustering quality:
Silhouette Score measures how similar an object is to its own cluster compared to other clusters. The range is from -1 to 1, where higher values indicate better-defined clusters. KMeans achieved the highest score (0.5321), indicating well-separated and cohesive clusters.
Davies-Bouldin Index evaluates intra-cluster similarity and inter-cluster differences, with lower values indicating better clustering. AgglomerativeClustering and WardHierarchical performed best (0.8446), closely followed by KMeans (0.8690).
Calinski-Harabasz Index (Variance Ratio Criterion) measures the ratio of between-cluster dispersion to within-cluster dispersion, with higher values indicating better-defined clusters. KMeans substantially outperformed other algorithms (17239.31).

PCA Visualization of Clustering Results
To visualize the high-dimensional clustering results, Principal Component Analysis (PCA) was applied to reduce the feature space to two dimensions while preserving maximum variance. Figure 1 shows the PCA visualization of the KMeans clustering results:

PCA Visualization of KMeans Clustering
The PCA projection demonstrates clear separation between most clusters, particularly those representing distinct anomaly types. The first two principal components captured approximately 73% of the total variance in the dataset, indicating that the visualization provides a reasonable representation of the cluster distribution.

Selection of Optimal Clustering Model
KMeans was selected as the optimal clustering algorithm for the following reasons:

Superior performance on key metrics: KMeans achieved the highest Silhouette Score (0.5321) and Calinski-Harabasz Index (17239.31), indicating well-separated clusters with high cohesion.
Appropriate cluster granularity: With 15 clusters, KMeans provided sufficient granularity to distinguish between different types of power quality anomalies while avoiding over-segmentation.
Computational efficiency: KMeans completed in significantly less time than hierarchical and spectral methods, making it more practical for large-scale deployment.
Interpretability: The centroids generated by KMeans provided clear, interpretable patterns that could be directly mapped to known power quality anomalies.
While AgglomerativeClustering showed a slightly better Davies-Bouldin Index, the overall pattern of metrics favored KMeans as the most balanced performer across all evaluation criteria.
Spectral Clustering performed poorly in this application, likely due to the complex structure of the power quality data that doesn't align well with the manifold assumptions of spectral methods. The negative Silhouette Score (-0.0949) suggests that many data points might have been assigned to inappropriate clusters.
The optimal number of clusters (k=15) for KMeans was determined through comprehensive evaluation of metrics for values of k ranging from 2 to 15, with particular focus on the Silhouette Score, which showed continuous improvement up to k=15, indicating meaningful cluster separation even at higher granularity.
In the next section, we will examine how these clusters were mapped to specific anomaly types and analyze their distribution across different locations in Cebu.

Clustering Metrics Across Varying Cluster Counts
To determine the optimal number of clusters and assess how each algorithm responds to varying values of k, clustering performance metrics were computed across a range of k=2 to k=15. Figure 2 illustrates the trend of Silhouette Score, Davies-Bouldin Index, and Calinski-Harabasz Index for each algorithm:

Figure 2. Clustering Metric Comparison across Varying Cluster Counts
Silhouette Score trends reveal that KMeans consistently improved as k increased, peaking at k=15, further supporting its selection. Agglomerative and Ward Hierarchical Clustering also demonstrated strong cohesion, while Spectral Clustering's performance declined at higher values of k, even becoming unstable.


Davies-Bouldin Index showed that lower values were generally achieved by Agglomerative and Ward Clustering, especially in the range k=10 to k=12, suggesting compact clusters with good separation. KMeans also performed well and maintained stability.


Calinski-Harabasz Index indicated that KMeans formed the most compact and well-separated clusters overall, with a clear maximum at k=15. Agglomerative and Ward methods showed competitive performance but peaked slightly earlier.


This comparative analysis across varying cluster counts provides robust support for choosing KMeans with k=15 as the optimal configuration. It not only achieved the best individual metric values but also demonstrated consistent improvement and stability across metrics.


